{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uploading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\persi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('input.txt','rt')\n",
    "text = file.read()\n",
    "corpus = []\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    corpus.append(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence tokenization example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence:\n",
      "Once more, on pain of death, all men depart.\n",
      "\n",
      "Result sequence :\n",
      "['once', 'more', 'on', 'pain', 'of', 'death', 'all', 'men', 'depart']\n"
     ]
    }
   ],
   "source": [
    "k = np.random.choice(len(sentences))\n",
    "print(f'Source sentence:\\n{sentences[k]}\\n\\nResult sequence :\\n{corpus[k]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict#Counter\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(seq, n):\n",
    "    it = iter(seq)\n",
    "    result = list(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        # using sort for context words because the tuples of the same words have to be equivalent\n",
    "        output = tuple(sorted(result[:n-1])), result[-1]\n",
    "        yield output\n",
    "    for elem in it:\n",
    "        result = result[1:] + [elem,]\n",
    "        output = tuple(sorted(result[:n-1])), result[-1]\n",
    "        yield output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, n_gram=2, mode='word'):\n",
    "        self.n_gram = n_gram\n",
    "        self.mode = mode\n",
    "\n",
    "    def build_model(self, text):\n",
    "        self.model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "        for sentence in text:\n",
    "            for condition, word in list(get_windows(sentence, self.n_gram)):\n",
    "                self.model[condition][word] += 1\n",
    "\n",
    "        for condition in self.model:\n",
    "            total_count = float(sum(self.model[condition].values()))\n",
    "            for word in self.model[condition]:\n",
    "                self.model[condition][word] /= total_count\n",
    "\n",
    "    def calculate_proba(self, sentence, print_ngram_pr=True):\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        words = [word.lower() for word in words if word.isalpha()]\n",
    "        if self.mode == 'character':\n",
    "            words = list(' '.join(words))\n",
    "            \n",
    "        proba = 1\n",
    "        for condition, word in list(get_windows(words, self.n_gram)):\n",
    "            ngram_pr = self.model[condition][word]\n",
    "            if print_ngram_pr:\n",
    "                print(f'n-gram {*condition, word} probability = {ngram_pr:.5f}, sentence probability = {proba:.5f}')\n",
    "            proba *= ngram_pr\n",
    "        print(f'\\nsentence probability = {proba:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram ('business', 'our', 'is') probability = 0.50000, sentence probability = 1.00000\n",
      "n-gram ('business', 'is', 'not') probability = 0.33333, sentence probability = 0.50000\n",
      "n-gram ('is', 'not', 'unknown') probability = 0.00893, sentence probability = 0.16667\n",
      "n-gram ('not', 'unknown', 'to') probability = 1.00000, sentence probability = 0.00149\n",
      "n-gram ('to', 'unknown', 'the') probability = 0.50000, sentence probability = 0.00149\n",
      "n-gram ('the', 'to', 'king') probability = 0.03886, sentence probability = 0.00074\n",
      "\n",
      "sentence probability = 0.00003\n"
     ]
    }
   ],
   "source": [
    "lm = LanguageModel(n_gram=3)\n",
    "lm.build_model(corpus)\n",
    "lm.calculate_proba('Our business is not unknown to the king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram ('business', 'our', 'is') probability = 0.50000, sentence probability = 1.00000\n",
      "n-gram ('business', 'is', 'not') probability = 0.33333, sentence probability = 0.50000\n",
      "n-gram ('is', 'not', 'unknown') probability = 0.00893, sentence probability = 0.16667\n",
      "n-gram ('not', 'unknown', 'to') probability = 1.00000, sentence probability = 0.00149\n",
      "n-gram ('to', 'unknown', 'the') probability = 0.50000, sentence probability = 0.00149\n",
      "n-gram ('the', 'to', 'boss') probability = 0.00000, sentence probability = 0.00074\n",
      "\n",
      "sentence probability = 0.00000\n"
     ]
    }
   ],
   "source": [
    "lm.calculate_proba('Our business is not unknown to the boss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how often the word \"boss\" appeared in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lord:\n",
      "Huntsman, I charge thee, tender well my hounds:\n",
      "Brach Merriman, the poor cur is emboss'd;\n",
      "And couple Clowder with the deep--mouth'd brach.\n",
      "GREMIO:\n",
      "First, as you know, my house within the city\n",
      "Is richly furnished with plate and gold;\n",
      "Basins and ewers to lave her dainty hands;\n",
      "My hangings all of Tyrian tapestry;\n",
      "In ivory coffers I have stuff'd my crowns;\n",
      "In cypress chests my arras counterpoints,\n",
      "Costly apparel, tents, and canopies,\n",
      "Fine linen, Turkey cushions boss'd with pearl,\n",
      "Valance of Venice gold in needlework,\n",
      "Pewter and brass and all things that belong\n",
      "To house or housekeeping: then, at my farm\n",
      "I have a hundred milch-kine to the pail,\n",
      "Sixscore fat oxen standing in my stalls,\n",
      "And all things answerable to this portion.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    if 'boss' in sentence:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word 'boss' appears in the text once and makes sense different from the expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's left most frequent words and add 'UNK', 'START', 'END' tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel2:\n",
    "    def __init__(self, n_gram=2, count_threshold=3):\n",
    "        self.n_gram = n_gram\n",
    "        self.count_threshold = count_threshold\n",
    "\n",
    "    def build_model(self, text):\n",
    "        self.model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.unk_token = \"<UNKNOWN>\"\n",
    "        self.start_token = \"<START>\"\n",
    "        self.end_token = \"<END>\"\n",
    "        self.counts = Counter({self.start_token: len(text), self.end_token: len(text), self.unk_token:self.count_threshold+1})\n",
    "        \n",
    "        # compute counts\n",
    "        for step, sentence in enumerate(text):\n",
    "            if not step % 1000:\n",
    "                print(\"working on {}kth line\".format(step // 1000), end='\\r')\n",
    "            for token in sentence:\n",
    "                self.counts[token] += 1\n",
    "                         \n",
    "        # prune vocab\n",
    "        print('number of token before prunning:', len(self.counts))\n",
    "        tokens_to_delete = []\n",
    "        for token, count in self.counts.items():\n",
    "            if count < self.count_threshold:\n",
    "                self.counts[\"<UNKNOWN>\"] += count\n",
    "                tokens_to_delete.append(token)\n",
    "        self.counts[\"<UNKNOWN>\"] -= self.count_threshold\n",
    "        for token in tokens_to_delete:\n",
    "            self.counts.pop(token)\n",
    "        self.vocab_size = len(self.counts)\n",
    "        print('after prunning:', self.vocab_size)\n",
    "        \n",
    "        # build new dataset                     \n",
    "        new_text = []\n",
    "        for sentence in text:\n",
    "            new_sentence = [self.start_token]\n",
    "            new_sentence += [token if token in self.counts else self.unk_token for token in sentence]\n",
    "            new_sentence += [self.end_token]\n",
    "            new_text.append(new_sentence)\n",
    "        \n",
    "        # build the model\n",
    "        for sentence in new_text:\n",
    "            for condition, word in list(get_windows(sentence, self.n_gram)):\n",
    "                self.model[condition][word] += 1\n",
    "\n",
    "        for condition in self.model:\n",
    "            total_count = float(sum(self.model[condition].values()))\n",
    "            for word in self.model[condition]:\n",
    "                self.model[condition][word] /= total_count\n",
    "\n",
    "    def calculate_proba(self, sentence, print_ngram_pr=True):\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        words = [word.lower() for word in words if word.isalpha()]\n",
    "        words = [word if word in self.counts else self.unk_token for word in words]\n",
    "            \n",
    "        proba = 1\n",
    "        for condition, word in list(get_windows(words, self.n_gram)):\n",
    "            ngram_pr = self.model[condition][word]\n",
    "            if print_ngram_pr:\n",
    "                print(f'n-gram {*condition, word} probability = {ngram_pr:.10f}, sentence probability = {proba:.10f}')\n",
    "            proba *= ngram_pr\n",
    "        print(f'\\nsentence probability = {proba:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of token before prunning: 11141\n",
      "after prunning: 4651\n",
      "n-gram ('business', 'our', 'is') probability = 0.5000000000, sentence probability = 1.0000000000\n",
      "n-gram ('business', 'is', 'not') probability = 0.3333333333, sentence probability = 0.5000000000\n",
      "n-gram ('is', 'not', 'unknown') probability = 0.0087719298, sentence probability = 0.1666666667\n",
      "n-gram ('not', 'unknown', 'to') probability = 1.0000000000, sentence probability = 0.0014619883\n",
      "n-gram ('to', 'unknown', 'the') probability = 0.5000000000, sentence probability = 0.0014619883\n",
      "n-gram ('the', 'to', 'king') probability = 0.0381679389, sentence probability = 0.0007309942\n",
      "\n",
      "sentence probability = 0.0000279005\n"
     ]
    }
   ],
   "source": [
    "lm2 = LanguageModel2(n_gram=3, count_threshold=3)\n",
    "lm2.build_model(corpus)\n",
    "lm2.calculate_proba('Our business is not unknown to the king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram ('business', 'our', 'is') probability = 0.5000000000, sentence probability = 1.0000000000\n",
      "n-gram ('business', 'is', 'not') probability = 0.3333333333, sentence probability = 0.5000000000\n",
      "n-gram ('is', 'not', 'unknown') probability = 0.0087719298, sentence probability = 0.1666666667\n",
      "n-gram ('not', 'unknown', 'to') probability = 1.0000000000, sentence probability = 0.0014619883\n",
      "n-gram ('to', 'unknown', 'the') probability = 0.5000000000, sentence probability = 0.0014619883\n",
      "n-gram ('the', 'to', '<UNKNOWN>') probability = 0.0890585242, sentence probability = 0.0007309942\n",
      "\n",
      "sentence probability = 0.0000651013\n"
     ]
    }
   ],
   "source": [
    "lm2.calculate_proba('Our business is not unknown to the boss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New model's prediction for the second sentence increased, even became more than the prediction for the first sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's combine unigram, bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(seq, n):\n",
    "    it = iter(seq)\n",
    "    result = list(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        output = tuple(result[:n-1]), result[-1]\n",
    "        yield output\n",
    "    for elem in it:\n",
    "        result = result[1:] + [elem,]\n",
    "        output = tuple(result[:n-1]), result[-1]\n",
    "        yield output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel3:\n",
    "    def __init__(self, lambda1=0.1, lambda2=0.3, lambda3=0.6, count_threshold=3):\n",
    "        self.count_threshold = count_threshold\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.lambda3 = lambda3\n",
    "\n",
    "    def build_model(self, text):\n",
    "        self.unk_token = \"<UNKNOWN>\"\n",
    "        self.start_token = \"<START>\"\n",
    "        self.end_token = \"<END>\"\n",
    "        self.uni_model = Counter({self.start_token: len(text), self.end_token: len(text), self.unk_token:self.count_threshold+1})\n",
    "        self.bi_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.tri_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        \n",
    "        # compute counts/uni-model's value\n",
    "        for step, sentence in enumerate(text):\n",
    "            if not step % 1000:\n",
    "                print(\"working on {}kth line\".format(step // 1000), end='\\r')\n",
    "            for token in sentence:\n",
    "                self.uni_model[token] += 1\n",
    "                         \n",
    "        # prune vocab\n",
    "        print('number of token before prunning:', len(self.uni_model))\n",
    "        tokens_to_delete = []\n",
    "        for token, count in self.uni_model.items():\n",
    "            if count < self.count_threshold:\n",
    "                self.uni_model[\"<UNKNOWN>\"] += count\n",
    "                tokens_to_delete.append(token)\n",
    "        self.uni_model[\"<UNKNOWN>\"] -= self.count_threshold\n",
    "        for token in tokens_to_delete:\n",
    "            self.uni_model.pop(token)\n",
    "        self.vocab_size = len(self.uni_model)\n",
    "        print('after prunning:', self.vocab_size)\n",
    "        \n",
    "        # build new dataset                     \n",
    "        new_text = []\n",
    "        for sentence in text:\n",
    "            new_sentence = [self.start_token]\n",
    "            new_sentence += [token if token in self.uni_model else self.unk_token for token in sentence]\n",
    "            new_sentence += [self.end_token]\n",
    "            new_text.append(new_sentence)\n",
    "        \n",
    "        # build models\n",
    "        for sentence in new_text:\n",
    "            for condition, word in list(get_windows(sentence, n=2)):\n",
    "                self.bi_model[condition][word] += 1\n",
    "            for condition, word in list(get_windows(sentence, n=3)):\n",
    "                self.tri_model[condition][word] += 1\n",
    "                self.tri_model[condition[::-1]][word] += 1\n",
    "        # unigram model\n",
    "        for word in self.uni_model:\n",
    "            self.uni_model[word] /= self.vocab_size\n",
    "        # bigram model\n",
    "        for condition in self.bi_model:\n",
    "            total_count = float(sum(self.bi_model[condition].values()))\n",
    "            for word in self.bi_model[condition]:\n",
    "                self.bi_model[condition][word] /= total_count\n",
    "        # trigram model\n",
    "        for condition in self.tri_model:\n",
    "            total_count = float(sum(self.tri_model[condition].values()))\n",
    "            for word in self.tri_model[condition]:\n",
    "                self.tri_model[condition][word] /= total_count\n",
    "\n",
    "    def calculate_proba(self, sentence, print_ngram_pr=True):\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        words = [word.lower() for word in words if word.isalpha()]\n",
    "        words = [word if word in self.uni_model else self.unk_token for word in words]\n",
    "            \n",
    "        proba = 1\n",
    "        for condition, word in list(get_windows(words, n=3)):\n",
    "            ngram_pr = self.lambda1 * self.uni_model[word]\n",
    "            ngram_pr += self.lambda2 * self.bi_model[condition[1]][word]\n",
    "            ngram_pr += self.lambda3 * self.tri_model[condition][word]\n",
    "            if print_ngram_pr:\n",
    "                print(f'n-gram {*condition, word} probability = {ngram_pr:.10f}, sentence probability = {proba:.10f}')\n",
    "            proba *= ngram_pr\n",
    "        print(f'\\nsentence probability = {proba:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of token before prunning: 11141\n",
      "after prunning: 4651\n",
      "n-gram ('our', 'business', 'is') probability = 0.3494732316, sentence probability = 1.0000000000\n",
      "n-gram ('business', 'is', 'not') probability = 0.2473876586, sentence probability = 0.3494732316\n",
      "n-gram ('is', 'not', 'unknown') probability = 0.0055211669, sentence probability = 0.0864553645\n",
      "n-gram ('not', 'unknown', 'to') probability = 0.7026660933, sentence probability = 0.0004773345\n",
      "n-gram ('unknown', 'to', 'the') probability = 0.4350892281, sentence probability = 0.0003354068\n",
      "n-gram ('to', 'the', 'king') probability = 0.0427459579, sentence probability = 0.0001459319\n",
      "\n",
      "sentence probability = 0.0000062380\n"
     ]
    }
   ],
   "source": [
    "lm3 = LanguageModel3(count_threshold=3)\n",
    "lm3.build_model(corpus)\n",
    "lm3.calculate_proba('Our business is not unknown to the king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram ('our', 'business', 'is') probability = 0.3494732316, sentence probability = 1.0000000000\n",
      "n-gram ('business', 'is', 'not') probability = 0.2473876586, sentence probability = 0.3494732316\n",
      "n-gram ('is', 'not', 'unknown') probability = 0.0055211669, sentence probability = 0.0864553645\n",
      "n-gram ('not', 'unknown', 'to') probability = 0.7026660933, sentence probability = 0.0004773345\n",
      "n-gram ('unknown', 'to', 'the') probability = 0.4350892281, sentence probability = 0.0003354068\n",
      "n-gram ('to', 'the', '<UNKNOWN>') probability = 0.2296982837, sentence probability = 0.0001459319\n",
      "\n",
      "sentence probability = 0.0000335203\n"
     ]
    }
   ],
   "source": [
    "lm3.calculate_proba('Our business is not unknown to the boss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
